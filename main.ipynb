{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DermaScan-Bangkit-2024-CapstoneProject/DermaScan-Machine-Learning/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "IN_COLAB = None\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    IN_COLAB = True\n",
    "else:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print(\"Running in Google Colab:\", IN_COLAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3JaZBiOUMYir"
   },
   "outputs": [],
   "source": [
    "%pip install -q kaggle"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "Fei7haGBMao6",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "16oF0UB4Mcq6",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "8H1zXhhTMeQ7",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "!cat ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z9amEM3pM2Rh",
    "outputId": "7ed64250-4504-4bba-ab61-3bf9e4f3a4bc",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# !cd ./Datasets\n",
    "!kaggle datasets download pacificrm/skindiseasedataset\n",
    "!kaggle datasets download surajghuwalewala/ham1000-segmentation-and-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qKXHMpQ37qe"
   },
   "source": [
    "### **Consideration Table**\n",
    "| Condition                  | Cancer Association       | Type                     |\n",
    "|----------------------------|--------------------------|--------------------------|\n",
    "| Actinic Keratosis          | Precancerous             | Potentially cancerous    |\n",
    "| Basal Cell Carcinoma       | Cancerous                | Cancerous                |\n",
    "| Bowenâ€™s Disease            | Early-stage cancer       | Cancerous                |\n",
    "| Melanoma                   | Cancerous                | Cancerous                |\n",
    "| Skin Cancer (General)      | Cancerous                | Cancerous                |\n",
    "| Moles                      | Generally benign         | Generally benign         |\n",
    "| Sun/Sunlight Damage        | Indirectly linked        | Risk factor for cancer   |\n",
    "| Benign Keratosis-like Lesions | Benign               | Non-cancerous            |\n",
    "| Benign Tumors              | Benign                   | Non-cancerous            |\n",
    "| Seborrheic Keratoses       | Benign                   | Non-cancerous            |\n",
    "| Vascular Tumors            | Mostly benign            | Mostly non-cancerous     |\n",
    "| Others (Acne, Eczema, etc.)| Benign                   | Non-cancerous            |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W8RskzDdGnRV",
    "outputId": "5a25721f-1ca8-4eaf-b496-6743725bf943"
   },
   "outputs": [],
   "source": [
    "content_path = \"/content\" if IN_COLAB else \".\"\n",
    "dataset_path = \"/content/drive/MyDrive/datasets\" if IN_COLAB else \"./Datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "for file_name in os.listdir(dataset_path):\n",
    "    if file_name.endswith('.zip'):\n",
    "        folder_name = os.path.join(dataset_path, file_name[:-4])\n",
    "        os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "        file_path = os.path.join(dataset_path, file_name)\n",
    "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(folder_name)\n",
    "\n",
    "        print(f\"Extracted {file_name} into folder: {folder_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def display_images(processed_images):\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))  # Create a 2x5 grid to display 10 images\n",
    "    axes = axes.flatten()  # Flatten the axes to make it easier to iterate\n",
    "\n",
    "    for img, ax in zip(processed_images, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')  # Turn off axes\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def draw_hair(image):\n",
    "    # Copy the original image so we don't modify it directly\n",
    "    num_hairs = random.randint(4, 7)\n",
    "    image_with_hair = image.copy()\n",
    "\n",
    "    # Get image dimensions\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # Define possible hair colors (in BGR format)\n",
    "    hair_colors = [(0, 0, 0), (50, 50, 50), (80, 80, 80)]\n",
    "\n",
    "    # Draw the specified number of hairs\n",
    "    for _ in range(num_hairs):\n",
    "        # Randomly choose the starting point\n",
    "        start_x = random.randint(0, width - 1)\n",
    "        start_y = random.randint(0, height - 1)\n",
    "\n",
    "        # Randomly choose the length and direction\n",
    "        length = random.randint(40, 150)\n",
    "        angle = random.randint(40, 360)\n",
    "        end_x = start_x + length * np.cos(np.radians(angle))\n",
    "        end_y = start_y + length * np.sin(np.radians(angle))\n",
    "\n",
    "        # Make sure the end point is within the image boundaries\n",
    "        end_x = np.clip(end_x, 0, width - 1)\n",
    "        end_y = np.clip(end_y, 0, height - 1)\n",
    "\n",
    "        # Randomly choose the hair color\n",
    "        color = random.choice(hair_colors)\n",
    "\n",
    "        # Draw the hair as a line on the image\n",
    "        thickness = random.randint(1, 2) # Random thickness for variation\n",
    "        cv2.line(image_with_hair, (int(start_x), int(start_y)), (int(end_x), int(end_y)), color, thickness)\n",
    "\n",
    "    return image_with_hair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_ham1000_path = dataset_path + \"/ham1000-segmentation-and-classification/\"\n",
    "csv_path = base_ham1000_path + \"GroundTruth.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df['image'] = base_ham1000_path + 'images/' + df['image'] + '.jpg'\n",
    "random_images = df['image'].tolist()[1:11]\n",
    "images_with_hair = [draw_hair(cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2RGB)) for img in random_images]\n",
    "display_images(images_with_hair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bresenham(x1, y1, x2, y2, r):\n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "    line_length = math.sqrt(dx**2 + dy**2)\n",
    "    steps = int(line_length / r)\n",
    "    x_inc = dx / steps\n",
    "    y_inc = dy / steps\n",
    "\n",
    "    xs = x1 + np.arange(steps) * x_inc\n",
    "    ys = y1 + np.arange(steps) * y_inc\n",
    "\n",
    "    return list(zip(xs, ys))\n",
    "\n",
    "def detection_points(source, new_img, linesP, r):\n",
    "    all_points = []\n",
    "    for line in linesP:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(new_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        intermedian_points = bresenham(x1, y1, x2, y2, r)\n",
    "        all_points.extend(intermedian_points)\n",
    "    return source, new_img, all_points\n",
    "\n",
    "def reduce_points(points):\n",
    "    points_array = np.array(points)\n",
    "    differences = np.abs(points_array[:, None] - points_array)\n",
    "    mask = np.all(differences > 2, axis=-1)\n",
    "    mask = np.all(mask, axis=1)\n",
    "    return points_array[mask].tolist()\n",
    "\n",
    "def histogram_distribution(H_flat_norm):\n",
    "    num_bins = 10\n",
    "    H = np.array(H_flat_norm)\n",
    "    hist, _ = np.histogram(H, bins=num_bins, range=(0, 1))\n",
    "    return np.var(hist)\n",
    "\n",
    "def get_density(points, gridsize, **kwargs):\n",
    "    xlim, ylim = [0, 600], [0, 450]\n",
    "    x, y = zip(*points)\n",
    "\n",
    "    D, _, _ = np.histogram2d(x, y, bins=gridsize, range=[xlim, ylim])\n",
    "    D_flat = D.flatten()\n",
    "    D_max = np.max(D_flat)\n",
    "    D_norm_flat = D_flat / D_max\n",
    "\n",
    "    variance = np.var(D_norm_flat)\n",
    "    std_dev = np.std(D_norm_flat)\n",
    "\n",
    "    hist_variance = histogram_distribution(D_norm_flat)\n",
    "    return D_max, hist_variance, std_dev, variance\n",
    "\n",
    "def plot_density(x, y, D):\n",
    "    xlim, ylim = [0, 600], [0, 450]\n",
    "    gridsize = 5\n",
    "    D_flat = D.flatten()\n",
    "    cmap = plt.cm.get_cmap('viridis_r')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    im = ax.imshow(D.T, origin='upper', extent=[xlim[0], xlim[1], ylim[1], ylim[0]], cmap=cmap)\n",
    "    ax.scatter(x, y, color='orange')\n",
    "\n",
    "    cbar = fig.colorbar(im, ax=ax, shrink=0.5)\n",
    "    cbar.set_label('Density')\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(D_flat, bins=gridsize**2, alpha=0.8, density=False)\n",
    "    plt.xlabel('Density')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "def hair_removal(image, file_name, **kwargs):\n",
    "\n",
    "    # height, width of image\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "\n",
    "    # Get r from the parameters\n",
    "    r = kwargs.get(\"r\")\n",
    "\n",
    "    # Define source image\n",
    "    source = image.copy()\n",
    "\n",
    "    # Define the desination image\n",
    "    new_img = image.copy()\n",
    "\n",
    "    # Define grayscale image for canny\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply canny edge detection\n",
    "    edges= cv2.Canny(gray,kwargs.get(\"canny_A\"), kwargs.get(\"canny_B\"), kwargs.get(\"aperture\"))\n",
    "\n",
    "    # Line detection with Probabilistic Line Transform\n",
    "    linesP = cv2.HoughLinesP(edges, cv2.HOUGH_PROBABILISTIC, np.pi / kwargs.get(\"hough_resolution\"),kwargs.get(\"hough_threshold\"),kwargs.get(\"hough_min_length\"),kwargs.get(\"hough_max_gap\"),kwargs.get(\"hough_iter\"))\n",
    "\n",
    "    # Process the lines if there are less than 600\n",
    "    if linesP is not None and len(linesP) < 600:\n",
    "        skip_this_image = False\n",
    "\n",
    "        source, new_img, all_points = detection_points(source,new_img,linesP,r)\n",
    "        max_density, histogram_variance, std_dev,variance = get_density(all_points,gridsize=5,**kwargs)\n",
    "\n",
    "        filtered_points = reduce_points(all_points)\n",
    "        filtered_points = all_points\n",
    "\n",
    "        if not skip_this_image and max_density > kwargs.get(\"max_density_cap\"):\n",
    "            # Skip if the histogram variance is greater than this max\n",
    "            if histogram_variance > kwargs.get(\"max_hist_variance\"):\n",
    "                skip_this_image=True\n",
    "\n",
    "            # Skip if the variance is too great\n",
    "            if variance > kwargs.get(\"max_variance_cap\"):\n",
    "                skip_this_image=True\n",
    "\n",
    "            if not skip_this_image and len(linesP) > kwargs.get(\"max_lines_cap\"):\n",
    "                if std_dev > kwargs.get(\"max_std_dev_cap\"):\n",
    "                    skip_this_image=True\n",
    "\n",
    "                elif not skip_this_image and max_density > kwargs.get(\"max_density_cap\") and (histogram_variance > kwargs.get(\"max_hist_variance_cap\") or std_dev>kwargs.get(\"max_std_dev_cap\")):\n",
    "                    skip_this_image=True\n",
    "\n",
    "        if not skip_this_image:\n",
    "\n",
    "          for i in range(0, 32):\n",
    "              for point in filtered_points:\n",
    "                  x1, y1 = map(int, point)\n",
    "                  if x1 > r and y1 > r and x1 < width - r and y1 < height - r:\n",
    "                      y_range = slice(y1 - r, y1 + r)\n",
    "                      x_range = slice(x1 - r, x1 + r)\n",
    "\n",
    "                      top = 0.25 * source[y_range, x1 - 2 * r]\n",
    "                      left = 0.25 * source[y1 - 2 * r, x_range]\n",
    "                      bottom = 0.25 * source[y1 + 2 * r, x_range]\n",
    "                      right = 0.25 * source[y_range, x1 + 2 * r]\n",
    "\n",
    "                      noise = np.random.uniform(-5, 5, (2 * r, 2 * r, 3))\n",
    "                      source[y_range, x_range] = left + top + right + bottom + noise\n",
    "\n",
    "          cv2.imwrite(os.path.join(kwargs['dest_folder'],  os.path.basename(file_name)), source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare width and height of the patches\n",
    "r=6\n",
    "\n",
    "#Set canny parameters\n",
    "canny_A = 100\n",
    "canny_B = 100\n",
    "aperture = 3\n",
    "L2gradient = False\n",
    "\n",
    "#Set HoughlinesP parameters\n",
    "hough_method = 'cv2.HOUGH_PROBABILISTIC'\n",
    "hough_resolution = 720   # the resolution of rho in degrees\n",
    "hough_threshold  = 35    # number of required votes\n",
    "hough_min_length = 1     # the minimum line length\n",
    "hough_max_gap    = 15    # maximum allowed gap\n",
    "hough_iter       = 16    # number of iterations\n",
    "\n",
    "# Set Thresholds\n",
    "max_lines_cap           = 99    # Check density above this cap\n",
    "max_density_cap         = 123   # Check density history variance above this cap\n",
    "max_hist_variance       = 30    # Maximum allowed density history variance\n",
    "max_hist_variance_cap   = 5     # Even distribution below this threshold\n",
    "max_std_dev_cap         = 0.30  # Even distribution below this threshold\n",
    "max_variance_cap        = 0.10  # Even distribution below this threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\"r\": r, \"canny_A\": canny_A, \"canny_B\": canny_B,\n",
    "            \"aperture\": aperture, \"L2gradient\": L2gradient,\"max_lines_cap\": max_lines_cap,\n",
    "            \"max_density_cap\": max_density_cap,\"max_hist_variance\":max_hist_variance,\n",
    "            \"max_hist_variance_cap\":max_hist_variance_cap,\"max_std_dev_cap\":max_std_dev_cap,\n",
    "            \"max_variance_cap\":max_variance_cap,\"hough_method\":hough_method,\"hough_resolution\":hough_resolution,\n",
    "            \"hough_threshold\":hough_threshold,\n",
    "            \"hough_min_length\":hough_min_length,\n",
    "            \"hough_max_gap\":hough_max_gap,\n",
    "            \"hough_iter\":hough_iter,\n",
    "            \"dest_folder\": \"dest\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "i = 0\n",
    "def process_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    # Apply hair_removal function with your parameters\n",
    "    if not os.path.exists(parameters[\"dest_folder\"]):\n",
    "        os.makedirs(parameters[\"dest_folder\"])\n",
    "    hair_removal(image, image_path, **parameters)\n",
    "    i = i + 1\n",
    "    print(i)\n",
    "\n",
    "image_paths = list(map(lambda x: os.path.join(base_ham1000_path + \"images\", x), filter(lambda x: x.endswith('.jpg'), os.listdir(base_ham1000_path + \"images\"))))\n",
    "print(image_paths[:5], len(image_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute hair removal with workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "with ThreadPoolExecutor(max_workers=14) as executor:\n",
    "    executor.map(process_image, image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Define the source and destination directories\n",
    "source_dir = parameters[\"dest_folder\"]\n",
    "dest_dir = base_ham1000_path + \"images\"\n",
    "\n",
    "# Get the list of preprocessed images\n",
    "preprocessed_images = os.listdir(source_dir)\n",
    "\n",
    "# Replace the original images with the preprocessed images\n",
    "for image_name in preprocessed_images:\n",
    "    source_path = os.path.join(source_dir, image_name)\n",
    "    dest_path = os.path.join(dest_dir, image_name)\n",
    "\n",
    "    # Copy the preprocessed image to the original directory\n",
    "    shutil.copy(source_path, dest_path)\n",
    "    print(f\"Replaced {dest_path} with preprocessed image.\")\n",
    "\n",
    "print(\"All images have been replaced with preprocessed images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by labels and Split HAM10000 to train-test 80:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "image_folder = './Datasets/ham1000-segmentation-and-classification/images'\n",
    "output_folder = image_folder + \"/labeled_splitted\"\n",
    "file_extension = \".jpg\"\n",
    "\n",
    "# Define a mapping of labels to folder-friendly names\n",
    "label_mapping = {\n",
    "    \"MEL\": \"melanoma\",\n",
    "    \"NV\": \"melanocytic_nevi\",\n",
    "    \"BCC\": \"basal_cell_carcinoma\",\n",
    "    \"AKIEC\": \"actinic_keratoses_and_bowens_disease\",\n",
    "    \"BKL\": \"benign_keratosis_like_lesions\",\n",
    "    \"DF\": \"dermatofibroma\",\n",
    "    \"VASC\": \"vascular_lesions\"\n",
    "}\n",
    "\n",
    "# Load CSV\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "# Split into train and test sets (80% train, 20% test, stratified by labels)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data.iloc[:, 1:], random_state=42)\n",
    "\n",
    "# Function to organize images into train or test directories\n",
    "def organize_images(dataframe, split_name):\n",
    "    for _, row in dataframe.iterrows():\n",
    "        filename = row['image'] + file_extension\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "\n",
    "        # Check if the image exists\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Image {filename} not found, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Move image based on label\n",
    "        for label, value in row.items():\n",
    "            if label == 'image':\n",
    "                continue\n",
    "            if value == 1:\n",
    "                folder_name = label_mapping[label]\n",
    "                split_dir = os.path.join(output_folder, split_name, folder_name)\n",
    "                os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "                # Copy the image\n",
    "                dest_path = os.path.join(split_dir, filename)\n",
    "                shutil.copy(image_path, dest_path)\n",
    "                print(f\"Moved {filename} to {split_dir}\")\n",
    "\n",
    "# Organize train and test images\n",
    "organize_images(train_data, \"train\")\n",
    "organize_images(test_data, \"test\")\n",
    "\n",
    "print(\"Train-test split and organization completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with skindiseasedataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "!cp -r ./Datasets/ham1000-segmentation-and-classification/labeled_split/ ./Datasets/merged\n",
    "!cp -r ./Datasets/skindiseasedataset/SkinDisease/ ./Datasets/merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Paths\n",
    "train_dir = dataset_path + \"/train\"\n",
    "test_dir = dataset_path + \"/test\"\n",
    "\n",
    "# Define parameters\n",
    "image_size = (128, 128)  # Resize images\n",
    "batch_size = 32\n",
    "\n",
    "# Load train and test datasets\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",  # Multiclass integer labels\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size\n",
    ")\n",
    "\n",
    "# Get class names\n",
    "class_names = train_ds.class_names\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "# Define cancerous classes\n",
    "cancerous_classes = {\"melanoma\", \"actinic_keratoses_and_bowens_disease\", \"basal_cell_carcinoma\", \"SkinCancer\"}\n",
    "\n",
    "# Convert class names to a tensor for TensorFlow compatibility\n",
    "class_names_tensor = tf.constant(class_names)\n",
    "\n",
    "# Mapping function\n",
    "def map_labels(image, label):\n",
    "    # Get class names for the batch using tf.gather\n",
    "    class_name = tf.gather(class_names_tensor, label)\n",
    "\n",
    "    # Check if class names are in cancerous classes\n",
    "    binary_label = tf.reduce_any(tf.equal(class_name[:, None], list(cancerous_classes)), axis=1)\n",
    "\n",
    "    # Cast the binary label to an integer (0 or 1)\n",
    "    binary_label = tf.cast(binary_label, tf.int32)\n",
    "\n",
    "    # Return both disease_output and cancer_output\n",
    "    return image, {\"disease_output\": label, \"cancer_output\": binary_label}\n",
    "\n",
    "# Apply mapping to datasets\n",
    "train_ds = train_ds.map(map_labels)\n",
    "test_ds = test_ds.map(map_labels)\n",
    "\n",
    "# Prefetch for performance\n",
    "train_ds = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "inputs = tf.keras.Input(shape=(128, 128, 3))\n",
    "x = tf.keras.layers.Rescaling(1.0 / 255)(inputs)\n",
    "x = tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\")(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "x = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "# Output for multiclass classification (disease)\n",
    "disease_output = tf.keras.layers.Dense(len(class_names), activation=\"softmax\", name=\"disease_output\")(x)\n",
    "\n",
    "# Output for binary classification (cancerous or non-cancerous)\n",
    "cancer_output = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"cancer_output\")(x)\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.Model(inputs=inputs, outputs=[disease_output, cancer_output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss={\n",
    "        \"disease_output\": \"sparse_categorical_crossentropy\",\n",
    "        \"cancer_output\": \"binary_crossentropy\"\n",
    "    },\n",
    "    metrics={\n",
    "        \"disease_output\": \"accuracy\",\n",
    "        \"cancer_output\": \"accuracy\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "results = model.evaluate(test_ds)\n",
    "print(\"Evaluation Results:\", results)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
